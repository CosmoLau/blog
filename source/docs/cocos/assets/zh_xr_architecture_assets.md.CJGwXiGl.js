import{_ as t,c as r,o as e,a4 as a}from"./chunks/framework.uQk9_EO2.js";const d="/docs/cocos/assets/create_xr_node.BEH_985t.png",o="/docs/cocos/assets/prefabs.Dcyn80sT.png",s="/docs/cocos/assets/material.Dtq4Rvjd.png",c="/docs/cocos/assets/model.C7kXSNg6.png",u=JSON.parse('{"title":"内置资源与预制体","description":"","frontmatter":{},"headers":[],"relativePath":"zh/xr/architecture/assets.md","filePath":"zh/xr/architecture/assets.md","lastUpdated":1712336288000}'),n={name:"zh/xr/architecture/assets.md"},i=a('<h1 id="内置资源与预制体" tabindex="-1">内置资源与预制体 <a class="header-anchor" href="#内置资源与预制体" aria-label="Permalink to &quot;内置资源与预制体&quot;">​</a></h1><p>在 Cocos Creator 扩展管理器中 <strong>开启XR扩展</strong> 之后就可以允许在编辑器中使用传统创建对象的方式创建 XR 对象。</p><p>在 层级管理器 右键选择 <strong>创建 -&gt; XR</strong>，右侧会出现当前可以创建的所有 XR 预制体。选择想要实例化生成的对象即可在场景中创建出来。</p><p><img src="'+d+'" alt="assets/create_xr_node.png"></p><table><thead><tr><th>名称</th><th>说明</th><th>包含组件</th></tr></thead><tbody><tr><td>XR Agent</td><td>现实世界主角相关的信息在虚拟场景中的代理节点，同时具有用于控制虚拟世界中 XR 主角的生命周期的功能。</td><td>TrackingOrigin</td></tr><tr><td>XR HMD</td><td>头戴显示器设备在虚拟世界中的抽象节点，基于 Camera 对象进行改造生成，用于同步现实世界中头戴显示器的输入信号并将引擎渲染结果输出至设备。</td><td>Camera<br>AudioSource<br>HMDCtrl<br>PoseTracker<br>TargetEye</td></tr><tr><td>AR Camera</td><td>抽象表式移动端设备带有 AR 能力的摄像机，用于来映射物理设备的摄像头 AR 功能。</td><td>Camera<br>PoseTracker<br>ARCameraMgr</td></tr><tr><td>Ray Interactor</td><td>用于进行远距离交互的射线交互器，包含对 XR 设备手柄控制器的 I/O 映射以及射线交互功能。</td><td>PoseTracker<br>XRController<br>RayInteractor<br>Line</td></tr><tr><td>Direct Interactor</td><td>用于进行近距离直接交互的交互器，同时也包含了对 XR 设备手柄控制器的 I/O 映射以及交互功能</td><td>PoseTracker<br>XRController<br>DirectInteractor</td></tr><tr><td>Gaze Pointer Interactor</td><td>用于进行凝视点交互的交互器，跟随头动，按凝视时间来触发交互行为</td><td>UITransform<br>RenderRoot2D<br>XRGazeInteractor</td></tr><tr><td>ScreenTouchInteractor</td><td>适用于手持移动端设备的屏幕手势交互起，将屏幕手势转化为交互行为同场景中的对象进行交互。</td><td>ScreenTouchInteractor</td></tr><tr><td>Locomotion Checker</td><td>运动检查器，充当所有虚拟运动驱动访问 XR Agent 的仲裁者，可以保证固定时间内对唯一的运动状态的维持。</td><td>LocomotionChecker</td></tr><tr><td>Teleportable</td><td>支持与交互器发生传送交互行为的交互物，可以传送 XR Agent 到此对象相关的一个位置。</td><td>Teleportable<br>InteractableEvents</td></tr><tr><td>Simple Interactable</td><td>简易的交互物对象，用户可以在此对象上自定义扩展任意的交互行为</td><td>InteractableEvents</td></tr><tr><td>Grab Interactable</td><td>支持与交互器发生抓取行为的交互物。</td><td>RigidBody<br>GrabInteractable<br>InteractableEvents</td></tr><tr><td>XR Simulator</td><td>用于预览XR内容，提供Web端、无线串流两种方式。</td><td>XRInteractiveSimulator</td></tr><tr><td>XR Video Player</td><td>XR视频播放器，支持在空间中播放窗口化、180 度、360 度模式的视频。</td><td>XRVideoPlayer<br>XRVideoController<br>XRVideoCaption</td></tr><tr><td>XRUI</td><td>可在空间中渲染和交互的 3D UI。</td><td>RaycastChecker<br>RenderRoot2D<br>BoxCollider</td></tr><tr><td>Plane Tracking</td><td>为应用赋能平面识别能力，在运行时使用设备 AR 能力识别出物理世界中的平面特征数据，并可以将这些平面数据可视化显示在应用程序中。</td><td>ARPlaneTracking</td></tr><tr><td>Image Tracking</td><td>为应用赋能图像识别能力，在运行时使用设备 AR 能力识别出 2D 图像资源。</td><td>ARImageTracking</td></tr><tr><td>Meshing</td><td>为应用赋能环境重构能力，根据现实环境创建 3D 网格。</td><td>ARMeshing</td></tr></tbody></table><h2 id="内置资源" tabindex="-1">内置资源 <a class="header-anchor" href="#内置资源" aria-label="Permalink to &quot;内置资源&quot;">​</a></h2><p>开启 XR 的扩展后，在内置资源数据库（xr-plugin）中会新增 XR 预制体、材质和模型等资源，可供用户直接使用。具体位置如下图所示。</p><h3 id="预制体资源" tabindex="-1">预制体资源 <a class="header-anchor" href="#预制体资源" aria-label="Permalink to &quot;预制体资源&quot;">​</a></h3><p><img src="'+o+'" alt="prefabs"></p><h3 id="材质资源" tabindex="-1">材质资源 <a class="header-anchor" href="#材质资源" aria-label="Permalink to &quot;材质资源&quot;">​</a></h3><p><img src="'+s+'" alt="material"></p><h3 id="模型资源" tabindex="-1">模型资源 <a class="header-anchor" href="#模型资源" aria-label="Permalink to &quot;模型资源&quot;">​</a></h3><p><img src="'+c+'" alt="model"></p>',13),l=[i];function h(b,R,p,_,m,g){return e(),r("div",null,l)}const I=t(n,[["render",h]]);export{u as __pageData,I as default};
