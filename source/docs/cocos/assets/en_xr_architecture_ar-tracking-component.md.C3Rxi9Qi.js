import{_ as t,c as e,o as a,a4 as n}from"./chunks/framework.uQk9_EO2.js";const i="/docs/cocos/assets/create-plane-tracking-node.BYttEzaw.png",r="/docs/cocos/assets/plane-tracking-factors.Dxm9sjZF.png",o="/docs/cocos/assets/plane-tracking-actions.BIQG78N4.png",c="/docs/cocos/assets/plane-tracking-display.CCElpiXJ.png",s="/docs/cocos/assets/plane-tracking-effect.CYYmmk94.png",d="/docs/cocos/assets/image-tracking-node.CFHFin-v.png",h="/docs/cocos/assets/image-tacking-comp.CKcaO0Za.png",l="/docs/cocos/assets/set-image-source.vAl8lKQU.png",g="/docs/cocos/assets/image-tracking-display.Qnuz1L15.png",p="/docs/cocos/assets/image-tracking-effect.THIpeaLA.png",m="/docs/cocos/assets/meshing-node.DOKwvav1.png",u="/docs/cocos/assets/meshing-comp.og-s45mm.png",f="/docs/cocos/assets/meshing-effect.BbZqElkD.jpeg",z=JSON.parse('{"title":"AR Automated Behavior Editing","description":"","frontmatter":{},"headers":[],"relativePath":"en/xr/architecture/ar-tracking-component.md","filePath":"en/xr/architecture/ar-tracking-component.md","lastUpdated":1712336288000}'),b={name:"en/xr/architecture/ar-tracking-component.md"},y=n('<h1 id="ar-automated-behavior-editing" tabindex="-1">AR Automated Behavior Editing <a class="header-anchor" href="#ar-automated-behavior-editing" aria-label="Permalink to &quot;AR Automated Behavior Editing&quot;">​</a></h1><p>In AR scenes, there is always an unknown dependency between virtual objects and real entities. If we can clearly and conveniently describe the conditional characteristics of real entities and execute matching behaviors based on these conditions, it can greatly simplify the handling of complex AR features for developers and allow them to focus on writing business-related code. Cocos CreatorXR provides AR automated behavior editing components that abstract common physical features and logical behaviors into elements that developers can freely combine. The graphical interface significantly reduces the cost and entry barrier for AR application development.</p><p>Each automated behavior editing component for a specific feature has its own unique feature library and action library. The following describes all the AR features supported by the automated behavior editing in the current version:</p><h2 id="plane-tracking" tabindex="-1">Plane Tracking <a class="header-anchor" href="#plane-tracking" aria-label="Permalink to &quot;Plane Tracking&quot;">​</a></h2><p>Right-click in the <strong>Hierarchy</strong> panel and choose <strong>Create -&gt; XR -&gt; Plane Tracking</strong> to create a plane agent node that can describe a plane entity in the physical world.</p><p><img src="'+i+'" alt="ar-tracking-component/create-plane-tracking-node.png"></p><p>Select the created <strong>Plane Tracking</strong> node, and in the <strong>Inspector</strong> panel, you can see the default <code>cc.ARPlaneTracking</code> component that has been added. Select the <strong>Factor</strong> or <strong>Action</strong> tab to view the existing features or actions. Click &quot;Add Factor&quot; or &quot;Add Action&quot; to add new items from the feature library or action library.</p><p><img src="'+r+'" alt="ar-tracking-component/plane-tracking-factors.png"></p><p><img src="'+o+'" alt="ar-tracking-component/plane-tracking-actions.png"></p><p>Drag the virtual object that needs to be displayed under the created <strong>Plane Tracking</strong> node and adjust its <code>size</code> and <code>scale</code> accordingly. Add the <strong>Display</strong> action item in the <strong>Actions</strong> section (already added by default), and the virtual object will be displayed when a plane that meets the conditions is recognized during runtime.</p><p><img src="'+c+'" alt="plane-tracking-display"></p><p><img src="'+s+'" alt="plane-tracking-effect"></p><h2 id="image-tracking" tabindex="-1">Image Tracking <a class="header-anchor" href="#image-tracking" aria-label="Permalink to &quot;Image Tracking&quot;">​</a></h2><p><strong>Image Tracking</strong> allows you to use the device&#39;s AR capabilities to recognize 2D image resources at runtime.</p><p>Right-click in the Hierarchy and select <strong>Create -&gt; XR -&gt; Image Tracking</strong> to create an image agent node that can describe an image entity in the physical world.</p><p><img src="'+d+'" alt="ar-tracking-component/image-tracking-node.png"></p><p>Select the created <strong>Image Tracking</strong> node, and in the Inspector panel, you can see the default <code>cc.ARImageTracking</code> component that has been added. In the <strong>Factor</strong> tab, under the <code>Image Source</code> property, add a new image resource.</p><p><img src="'+h+'" alt="ar-tracking-component/image-tacking-comp.png"></p><p>Drag and drop or directly select an image resource from the <code>Assets</code> window in the <code>Image</code> property. In the scene editor, you can see the currently referenced image and set its default physical size.</p><p><img src="'+l+'" alt="set-image-source"></p><p>Drag the virtual object that needs to be displayed under the created <strong>Image Tracking</strong> node and adjust its <code>size</code> and <code>scale</code> accordingly. Add the <strong>Display</strong> action item in the <strong>Actions</strong> section (already added by default), and the virtual object will be displayed when the image is recognized during runtime.</p><p><img src="'+g+'" alt="image-tracking-display"></p><p><img src="'+p+'" alt="image-tracking-effect"></p><h2 id="meshing-experimental" tabindex="-1"><strong>Meshing（Experimental）</strong> <a class="header-anchor" href="#meshing-experimental" aria-label="Permalink to &quot;**Meshing（Experimental）**&quot;">​</a></h2><p>Currently, the <strong>Meshing</strong> feature only works on iOS devices with depth scene reconstruction capabilities (such as iPhone/iPad Pro series with LiDAR scanner). <strong>Meshing</strong> allows you to create 3D meshes based on the real environment.</p><p>Right-click in the Hierarchy and select <strong>Create -&gt; XR -&gt; Meshing</strong> to create a Meshing agent node.</p><p><img src="'+m+'" alt="ar-tracking-component/meshing-node.png"></p><p>In the <code>cc.ARMeshing</code> component&#39;s <code>Mesh Visualizer</code> property, select the desired mesh visualization effect.</p><p><img src="'+u+'" alt="ar-tracking-component/meshing-comp.png"></p><p>This will enable real-time surface meshing based on the physical environment during runtime.</p><p><img src="'+f+'" alt="meshing-effect"></p><h2 id="feature-library" tabindex="-1">Feature Library <a class="header-anchor" href="#feature-library" aria-label="Permalink to &quot;Feature Library&quot;">​</a></h2><p>Currently, you can add the following features:</p><table><thead><tr><th>Feature</th><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td>Plane Direction</td><td></td><td>Specifies the required orientation for the plane. The plane can be set to a specific direction (horizontal, vertical, or other).</td></tr><tr><td>Plane Size</td><td></td><td>Sets the required size for the plane. When setting the size, you can choose to restrict the minimum/maximum size range of the plane.</td></tr><tr><td>Image Source</td><td>Image</td><td>Sets the image resource for Image Tracking.</td></tr><tr><td></td><td>Enable Physical Size</td><td>When enabled, the recognized image will default to the specified physical size as the size of the real-world image, without calculating the image size based on depth features. This can speed up the recognition process.</td></tr><tr><td></td><td>ImagePhysicalSize</td><td>Sets the physical size constraint for the calibrated image (in meters). When you change the width or height value, the other value will be automatically calculated based on the aspect ratio.</td></tr></tbody></table><h3 id="action-library" tabindex="-1">Action Library <a class="header-anchor" href="#action-library" aria-label="Permalink to &quot;Action Library&quot;">​</a></h3><p>Currently, you can add the following actions:</p><table><thead><tr><th>Action</th><th>Attribute</th><th>Description</th></tr></thead><tbody><tr><td>Display</td><td></td><td>Activates the child objects if all the features of the automation behavior editor component match the real-world entities; otherwise, disables the child objects.</td></tr><tr><td></td><td>Display Children Node</td><td>When enabled, displays the child nodes under the Tracking node by default.</td></tr><tr><td></td><td>Stop Tracking</td><td>Disables AR tracking for this node when the specified conditions are met.</td></tr><tr><td></td><td>Reset When Loss</td><td>Determines whether the behavior of the child nodes should be reset when tracking is lost.</td></tr><tr><td>Align</td><td></td><td>Specifies the alignment relationship between the position of the proxy node and the position of the real-world entity.</td></tr><tr><td></td><td>Towards</td><td>Sets the orientation of the child object. If set to Local_Up, it uses the pose of the child object directly. If set to World_Up, the child object&#39;s Y-axis will always align with the world coordinate&#39;s up direction.</td></tr><tr><td></td><td>Face to Camera</td><td>When enabled, the child object faces the direction of the AR Camera along the Z-axis.</td></tr><tr><td></td><td>MatchTrackingUpdate</td><td>When the real-world data matched by this node is updated, the layout and alignment effects are also refreshed.</td></tr><tr><td>Surface Overlay</td><td></td><td>Replaces the original visualization effect with the specified prefab when the conditions are met.</td></tr><tr><td></td><td>Surface Offset</td><td>Replaces the original visualization effect with the specified prefab when the conditions are met.</td></tr><tr><td></td><td>Replace Visualizer</td><td>Disables and replaces the tracking visualization effect after creation.</td></tr><tr><td>Adaptive Scale</td><td></td><td>Scales the child object based on the boundaries of the matched AR object.</td></tr><tr><td></td><td>Max Scale</td><td>Sets the maximum limit for scaling adjustment.</td></tr><tr><td></td><td>Match Tracking Update</td><td>Determines whether the behavior of scaling should be continuously refreshed along with tracking.</td></tr><tr><td>Track Event</td><td></td><td>Collection of events called during the matching of tracking features.</td></tr><tr><td></td><td>on Track Success</td><td>Event called when tracking is successful.</td></tr><tr><td></td><td>on Track Refresh</td><td>Event called when tracking information is refreshed.</td></tr><tr><td></td><td>on Track Loss</td><td>Event called when tracking is lost.</td></tr><tr><td></td><td>on Track Timeout</td><td>Event called when tracking times out. You can set the time for tracking check, and if no successful tracking data is matched within this time range, the tracking failure event will be triggered.</td></tr></tbody></table>',37),k=[y];function w(_,v,A,T,R,S){return a(),e("div",null,k)}const I=t(b,[["render",w]]);export{z as __pageData,I as default};
